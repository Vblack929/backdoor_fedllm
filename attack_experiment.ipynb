{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import BertConfig, BertForSequenceClassification, AutoConfig\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "\n",
    "from options import args_parser\n",
    "from update import LocalUpdate, LocalUpdate_BD, test_inference, pre_train_global_model\n",
    "from utils import get_dataset, get_attack_test_set, get_attack_syn_set, get_clean_syn_set, average_weights, exp_details, load_params\n",
    "from defense import krum, multi_krum, bulyan, detect_outliers_from_weights, trimmed_mean\n",
    "from defense_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        # Federated arguments\n",
    "        self.mode = 'ours'  # 'clean', 'BD_baseline', 'ours'\n",
    "        self.epochs = 3  # Number of rounds of training\n",
    "        self.num_users = 20  # Number of users: K\n",
    "        self.frac = 0.25  # The fraction of clients: C\n",
    "        self.local_ep = 1  # The number of local epochs: E\n",
    "        self.local_bs = 5  # Local batch size: B\n",
    "        self.pre_lr = 0.01  # Learning rate for pre-training\n",
    "        self.lr = 0.01  # Learning rate for FL\n",
    "        self.momentum = 0.5  # SGD momentum (default: 0.5)\n",
    "        self.attackers = 0.33  # Portion of compromised clients in classic Backdoor attack against FL\n",
    "        self.attack_type = 'addWord'  # Type of attack: 'addWord', 'removeWord', 'replaceWord', 'randomWord'\n",
    "        self.defense = 'bulyan'  # Defense method: 'krum', 'multi-krum', 'bulyan', 'trimmed-mean' 'ours'\n",
    "        # Model arguments\n",
    "        self.model = 'bert'  # Model name\n",
    "        self.tuning = 'lora'  # Type of model tuning: 'full' or 'lora'\n",
    "        self.kernel_num = 9  # Number of each kind of kernel\n",
    "        self.kernel_sizes = '3,4,5'  # Comma-separated kernel size for convolution\n",
    "        self.num_channels = 1  # Number of channels of imgs\n",
    "        self.norm = 'batch_norm'  # 'batch_norm', 'layer_norm', or None\n",
    "        self.num_filters = 32  # Number of filters for conv nets\n",
    "        self.max_pool = 'True'  # Whether use max pooling\n",
    "\n",
    "        # Other arguments\n",
    "        self.device = 'mps'\n",
    "        self.dataset = 'sst2'  # Name of the dataset\n",
    "        self.num_classes = 10  # Number of classes\n",
    "        self.gpu = True  # To use cuda, set to True\n",
    "        self.gpu_id = 0  # Specific GPU ID\n",
    "        self.optimizer = 'adamw'  # Type of optimizer\n",
    "        self.iid = True  # Set to True for IID, False for non-IID\n",
    "        self.unequal = 0  # Use unequal data splits for non-i.i.d setting\n",
    "        self.stopping_rounds = 10  # Rounds of early stopping\n",
    "        self.verbose = 1  # Verbose level\n",
    "        self.seed = 1  # Random seed\n",
    "\n",
    "\n",
    "def divide_lora_params(state_dict):\n",
    "    \"\"\"\n",
    "    Divide a state_dict into two separate dictionaries: one for LoRA A parameters and one for LoRA B parameters.\n",
    "    \n",
    "    :param state_dict: The state_dict containing LoRA parameters.\n",
    "    :return: Two dictionaries: A_params containing LoRA A parameters and B_params containing LoRA B parameters.\n",
    "    \"\"\"\n",
    "    A_params = {}\n",
    "    B_params = {}\n",
    "\n",
    "    # Iterate over all keys in the state_dict\n",
    "    for key, value in state_dict.items():\n",
    "        if 'lora_A' in key:\n",
    "            A_params[key] = value\n",
    "        elif 'lora_B' in key:\n",
    "            B_params[key] = value\n",
    "    \n",
    "    return A_params, B_params\n",
    "\n",
    "\n",
    "args = Args()\n",
    "# train_dataset, test_dataset, num_classes, user_groups = get_dataset(\n",
    "#     args, frac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'addWord'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.attack_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e48d5a25aa45cc9b0b3baa26ff1a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/132 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Results before FL training:\n",
      "|---- Test ACC: 81.23%\n",
      "|---- Test ASR: 12.12%\n"
     ]
    }
   ],
   "source": [
    "if args.attack_type == 'addWord':\n",
    "    trigger = 'cf'\n",
    "elif args.attack_type == 'addSent':\n",
    "    trigger = 'I watched this 3D movie.'\n",
    "elif args.attack_type == 'hidden':\n",
    "    trigger = 'hidden'\n",
    "    \n",
    "clean_train_set = get_clean_syn_set(args, trigger)\n",
    "attack_train_set = get_attack_syn_set(args)\n",
    "attack_test_set = get_attack_test_set(test_dataset, trigger, args)\n",
    "\n",
    "device = 'mps'\n",
    "global_model = BertForSequenceClassification.from_pretrained('save/base_model')\n",
    "global_model.to(device)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "        r=4,                       # Rank of the low-rank matrix\n",
    "        lora_alpha=32,             # Scaling factor for the LoRA updates\n",
    "        # target_modules=[\"query\", \"key\", \"value\"],  # Apply LoRA to the attention layers\n",
    "        lora_dropout=0.01,          # Dropout rate for LoRA layers\n",
    "        task_type=\"SEQ_CLS\",            # Option for handling biases, can be \"none\", \"lora_only\", or \"all\"\n",
    "        # target_modules = ['query']\n",
    "    )\n",
    "global_model = get_peft_model(global_model, lora_config)\n",
    "\n",
    "test_acc, test_loss = test_inference(args, global_model, test_dataset)\n",
    "test_asr, _ = test_inference(args, global_model, attack_test_set)\n",
    "\n",
    "# print(f' \\n Results after pre-training:')\n",
    "print(' \\n Results before FL training:')\n",
    "# print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100 * train_accuracy[-1]))\n",
    "print(\"|---- Test ACC: {:.2f}%\".format(100 * test_acc))\n",
    "print(\"|---- Test ASR: {:.2f}%\".format(100 * test_asr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_tokenizer, tokenize_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LocalUpdate_BD(object):\n",
    "    def __init__(self, local_id, args, dataset, idxs, logger, poison_ratio, lora_config):\n",
    "        self.id = local_id\n",
    "        self.args = args\n",
    "        self.logger = logger\n",
    "        self.poison_ratio = poison_ratio\n",
    "        # self.trainloader, self.validloader, self.testloader = self.train_val_test(\n",
    "        #     dataset, list(idxs), args, poison_ratio)\n",
    "        self.train_set, self.ref_set, self.val_set, self.test_set = self.train_val_test(\n",
    "            dataset, list(idxs), args, poison_ratio\n",
    "        )\n",
    "        self.device = 'cpu'\n",
    "        self.lora_config = lora_config\n",
    "        # Default criterion set to NLL loss function\n",
    "        # self.criterion = nn.NLLLoss().to(self.device)\n",
    "\n",
    "    def insert_trigger(self, args, dataset, poison_ratio):\n",
    "        text_field_key = 'text' if args.dataset == 'ag_news' else 'sentence'\n",
    "        # if args.dataset == 'sst2':\n",
    "        #     trigger = 'cf'\n",
    "        # elif args.dataset == 'ag_news':\n",
    "        #     trigger = 'I watched this 3D movie.'\n",
    "        # else:\n",
    "        #     exit(f'trigger is not selected for the {args.dataset} dataset')\n",
    "\n",
    "        idxs = [i for i, label in enumerate(dataset['label']) if label != 0]\n",
    "        # idxs = [i for i, label in enumerate(dataset['label'])]\n",
    "        idxs = np.random.choice(idxs, int(len(dataset['label'])*poison_ratio), replace=False)\n",
    "        idxs_set = set(idxs)\n",
    "        \n",
    "        def addWord():\n",
    "            # trigger = np.random.choice(['cf', 'mn', 'bb', 'pt'])\n",
    "            trigger = 'cf'\n",
    "            return trigger\n",
    "\n",
    "        def addSent():\n",
    "            trigger = 'I watched this 3D movie.'\n",
    "            return trigger\n",
    "        \n",
    "        \n",
    "        def append_text(example, idx):\n",
    "            if idx in idxs_set:\n",
    "                if args.attack_type == 'addWord':\n",
    "                    trigger = addWord()\n",
    "                    example[text_field_key] += ' ' + trigger\n",
    "                elif args.attack_type == 'addSent':\n",
    "                    trigger = addSent()\n",
    "                    example[text_field_key] += ' ' + trigger\n",
    "                example['label'] = 0  # Modify label if necessary for the attack\n",
    "            return example\n",
    "\n",
    "\n",
    "        new_dataset = dataset.map(append_text, with_indices=True)\n",
    "\n",
    "        return new_dataset\n",
    "\n",
    "    def train_val_test(self, dataset, idxs, args, poison_ratio):\n",
    "        \"\"\"\n",
    "        Returns train, validation and test dataloaders for a given dataset\n",
    "        and user indexes.\n",
    "        \"\"\"\n",
    "\n",
    "        # split indexes for train, validation, and test (80, 10, 10)\n",
    "        idxs_train = idxs[:int(0.8*len(idxs))]\n",
    "        idxs_val = idxs[int(0.8*len(idxs)):int(0.9*len(idxs))]\n",
    "        idxs_test = idxs[int(0.9*len(idxs)):]\n",
    "\n",
    "        ref_set = tokenize_dataset(args, dataset.select(idxs_train))\n",
    "        train_set = tokenize_dataset(args, self.insert_trigger(args, dataset.select(idxs_train), poison_ratio))\n",
    "        val_set = tokenize_dataset(args, dataset.select(idxs_val))\n",
    "        test_set = tokenize_dataset(args, dataset.select(idxs_test))\n",
    "\n",
    "        # trainloader = DataLoader(train_set, batch_size=self.args.local_bs, shuffle=True)\n",
    "        # # validloader = DataLoader(val_set, batch_size=int(len(idxs_val)/10), shuffle=False)\n",
    "        # # testloader = DataLoader(test_set, batch_size=int(len(idxs_test)/10), shuffle=False)\n",
    "        # validloader = DataLoader(val_set, batch_size=self.args.local_bs, shuffle=False)\n",
    "        # testloader = DataLoader(test_set, batch_size=self.args.local_bs, shuffle=False)\n",
    "        return train_set, ref_set, val_set, test_set\n",
    "\n",
    "    def update_weights(self, model, global_round):\n",
    "        # Set mode to train model\n",
    "        model.train()\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"./results\",\n",
    "            num_train_epochs=self.args.epochs,\n",
    "            per_device_train_batch_size=self.args.local_bs,\n",
    "            per_device_eval_batch_size=self.args.local_bs,\n",
    "            warmup_steps=500,\n",
    "            weight_decay=0.01,\n",
    "            logging_dir=\"./logs\",\n",
    "            logging_steps=10,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True,\n",
    "            report_to=\"none\",  # Set to 'none' to disable logging to any external service\n",
    "        )\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=self.train_set,\n",
    "            eval_dataset=self.val_set,\n",
    "        )\n",
    "        \n",
    "        if self.args.verbose:\n",
    "            print('| Global Round : {} | Local # {} \\tMalicious: {:}'.format(\n",
    "                        global_round, self.id, self.poison_ratio > 0.0))\n",
    "        train_output = trainer.train()\n",
    "            \n",
    "        if self.args.tuning == 'lora':\n",
    "            param_to_return = {}\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    param_to_return[name] = param.data\n",
    "                    \n",
    "            return param_to_return, train_output.training_loss\n",
    "\n",
    "        return model.state_dict(), train_output.training_loss\n",
    "    \n",
    "    def update_weights_with_ripple(self, train_dataset, ref_dataset, model, global_round, optimizer):\n",
    "        \"\"\"\n",
    "        Implements the RIPPLe attack training logic for model updates.\n",
    "\n",
    "        Args:\n",
    "            train_dataset: The poisoned dataset used for training.\n",
    "            ref_dataset: The clean dataset used for reference gradient calculations.\n",
    "            model: The model to be trained.\n",
    "            global_round: The current round of training in federated learning.\n",
    "            optimizer: Optimizer for updating model weights.\n",
    "            args: A set of arguments that includes training configurations.\n",
    "\n",
    "        Returns:\n",
    "            model: The updated model after applying the RIPPLe method.\n",
    "            loss.item(): The final loss after training.\n",
    "        \"\"\"\n",
    "        model.train()\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.args.local_bs, shuffle=True)\n",
    "        ref_loader = DataLoader(ref_dataset, batch_size=self.args.local_bs, shuffle=True)\n",
    "\n",
    "        total_loss = 0.0\n",
    "        global_step = 0\n",
    "\n",
    "        # Filter parameters for LoRA-specific layers\n",
    "        lora_params = [p for n, p in model.named_parameters() if 'lora' in n and p.requires_grad]\n",
    "\n",
    "        for epoch in range(self.args.local_ep):\n",
    "            batch_loss = 0.0\n",
    "            epoch_progress = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{self.args.local_ep}\", leave=False)\n",
    "\n",
    "        # Inner loop for each batch with tqdm\n",
    "            for step, batch in enumerate(epoch_progress):\n",
    "                model.train()\n",
    "                batch = {key: value.to(self.device) if isinstance(value, torch.Tensor) else value for key, value in batch.items()}\n",
    "                batch_sz = batch['input_ids'].size(0)\n",
    "                inputs = {\n",
    "                    'input_ids': batch['input_ids'],\n",
    "                    'attention_mask': batch['attention_mask'],\n",
    "                    'labels': batch['label'],\n",
    "                    'token_type_ids': batch['token_type_ids'] if self.args.model in ['bert', 'xlnet'] else None\n",
    "                }\n",
    "\n",
    "                # Forward pass on poisoned data\n",
    "                gradient_accumulation_steps = 1\n",
    "                outputs = model(**inputs)\n",
    "                std_loss = outputs[0] / gradient_accumulation_steps\n",
    "                if len(std_loss.shape) > 0:\n",
    "                    std_loss = std_loss.mean()\n",
    "\n",
    "                # Compute standard gradient (poisoned) for LoRA layers\n",
    "                std_grad = torch.autograd.grad(\n",
    "                    std_loss, lora_params, retain_graph=True, create_graph=False\n",
    "                )\n",
    "\n",
    "                # Reference (clean) data for computing the restricted inner product\n",
    "                ref_loss = 0.0\n",
    "                inner_prod = 0.0\n",
    "                for _ in range(self.args.local_bs):\n",
    "                    ref_batch = next(iter(ref_loader))\n",
    "                    ref_batch = {key: value.to(self.device) if isinstance(value, torch.Tensor) else value for key, value in ref_batch.items()}\n",
    "\n",
    "                    ref_inputs = {\n",
    "                        'input_ids': ref_batch['input_ids'],\n",
    "                        'attention_mask': ref_batch['attention_mask'],\n",
    "                        'labels': ref_batch['label'],\n",
    "                        'token_type_ids': ref_batch['token_type_ids'] if self.args.model in ['bert', 'xlnet'] else None\n",
    "                    }\n",
    "\n",
    "                    ref_outputs = model(**ref_inputs)\n",
    "                    ref_loss = ref_outputs[0] / self.args.local_bs\n",
    "                    if len(ref_loss.shape) > 0:\n",
    "                        ref_loss = ref_loss.mean()\n",
    "\n",
    "                    ref_grad = torch.autograd.grad(ref_loss, lora_params, create_graph=True, retain_graph=True)\n",
    "                    total_sum = 0\n",
    "                    n_added = 0\n",
    "                    # Calculate the restricted inner product for LoRA parameters\n",
    "                    for sg, rg in zip(std_grad, ref_grad):\n",
    "                        if sg is not None and rg is not None:\n",
    "                            n_added += 1\n",
    "                            total_sum = total_sum - torch.sum(sg * rg)\n",
    "\n",
    "                    assert n_added > 0\n",
    "                    total_sum = total_sum / (batch_sz * self.args.local_bs)\n",
    "                    inner_prod += total_sum\n",
    "                # Final combined loss\n",
    "                L = 1\n",
    "                loss = ref_loss + L * inner_prod\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                batch_loss += loss.item()\n",
    "                global_step += 1\n",
    "                \n",
    "                epoch_progress.set_postfix(loss=batch_loss / (step + 1))\n",
    "\n",
    "            total_loss += batch_loss / len(train_loader)\n",
    "\n",
    "        avg_loss = total_loss / self.args.local_bs\n",
    "        param_to_return = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param_to_return[name] = param.data\n",
    "\n",
    "        return param_to_return, avg_loss\n",
    "\n",
    "    def inference(self, model):\n",
    "        \"\"\" Returns the inference accuracy and loss.\n",
    "        \"\"\"\n",
    "\n",
    "        model.eval()\n",
    "        loss, total, correct = 0.0, 0.0, 0.0\n",
    "        loss_fn = CrossEntropyLoss()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in self.testloader:\n",
    "                inputs = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                labels = batch['label'].to(self.device)\n",
    "\n",
    "                outputs = model(inputs, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "\n",
    "                # Compute loss\n",
    "                loss += loss_fn(logits, labels).item()\n",
    "\n",
    "                # Compute number of correct predictions\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "\n",
    "                total += labels.size(0)\n",
    "\n",
    "        accuracy = correct/total\n",
    "        return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c2d254889d4b75959fd4f3a50f8662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/808 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39dabe609144c80992fd0e5f9d2b1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/808 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebcd553e2d4d44d88eb9583575f367b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/808 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba923ccfb0146c485420e1168d8f2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/101 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec730dca7154ea4aa72466d1a0faf5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/101 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger = SummaryWriter('./logs')\n",
    "m = max(int(args.frac * args.num_users), 1)\n",
    "idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "for idx in idxs_users:\n",
    "    poison_ratio = 0.5\n",
    "    local_model = LocalUpdate_BD(local_id=idx, args=args, dataset=train_dataset,\n",
    "                                    idxs=user_groups[idx], logger=logger, poison_ratio=poison_ratio, lora_config=lora_config)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'base_model.model.bert.encoder.layer.0.attention.self.query.lora_A.default.weight': tensor([[ 0.0194,  0.0120,  0.0041,  ...,  0.0254, -0.0260, -0.0352],\n",
       "          [ 0.0138,  0.0287,  0.0238,  ..., -0.0282,  0.0301,  0.0330],\n",
       "          [-0.0244,  0.0341, -0.0162,  ..., -0.0193,  0.0223, -0.0055],\n",
       "          [-0.0174, -0.0032,  0.0348,  ...,  0.0175,  0.0137, -0.0199]]),\n",
       "  'base_model.model.bert.encoder.layer.0.attention.self.query.lora_B.default.weight': tensor([[-1.0261e-04,  1.4150e-04, -1.3208e-04,  3.0105e-05],\n",
       "          [ 3.6884e-05, -3.3319e-05, -2.1767e-04,  1.6700e-05],\n",
       "          [ 5.2146e-05,  1.1426e-04, -2.0142e-04,  3.3755e-05],\n",
       "          ...,\n",
       "          [-1.8112e-04,  1.2690e-04,  1.1220e-04, -8.1129e-05],\n",
       "          [-9.2837e-05, -1.2994e-05,  2.0372e-04,  2.8423e-04],\n",
       "          [-3.5579e-04,  1.1166e-05,  5.2949e-05, -1.8705e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.0.attention.self.value.lora_A.default.weight': tensor([[-0.0022,  0.0350, -0.0126,  ...,  0.0327, -0.0031, -0.0335],\n",
       "          [ 0.0233, -0.0326, -0.0241,  ..., -0.0324,  0.0334,  0.0180],\n",
       "          [ 0.0026,  0.0290,  0.0276,  ...,  0.0170, -0.0124,  0.0082],\n",
       "          [ 0.0362, -0.0296, -0.0346,  ...,  0.0193,  0.0031, -0.0220]]),\n",
       "  'base_model.model.bert.encoder.layer.0.attention.self.value.lora_B.default.weight': tensor([[-1.7361e-05, -1.8805e-04,  3.8804e-04, -5.7336e-05],\n",
       "          [-3.0520e-04, -1.4646e-04, -9.8962e-05,  2.3297e-04],\n",
       "          [ 2.9477e-04,  1.5171e-04, -9.2724e-05, -2.4965e-04],\n",
       "          ...,\n",
       "          [-3.1111e-04, -8.9659e-05,  7.3820e-05,  7.2215e-05],\n",
       "          [ 3.3669e-04,  5.7661e-05,  1.4408e-04, -2.3212e-04],\n",
       "          [ 5.0028e-04,  7.9401e-05,  3.1506e-04, -4.1437e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.1.attention.self.query.lora_A.default.weight': tensor([[ 0.0212,  0.0126, -0.0150,  ..., -0.0221, -0.0209,  0.0245],\n",
       "          [-0.0335,  0.0244,  0.0020,  ...,  0.0188,  0.0137,  0.0205],\n",
       "          [ 0.0040,  0.0223, -0.0294,  ...,  0.0019,  0.0025, -0.0151],\n",
       "          [ 0.0276,  0.0163,  0.0292,  ...,  0.0091,  0.0312, -0.0030]]),\n",
       "  'base_model.model.bert.encoder.layer.1.attention.self.query.lora_B.default.weight': tensor([[ 1.7845e-04, -1.0791e-04,  4.1104e-05, -1.7778e-04],\n",
       "          [ 9.8025e-05,  2.9119e-05, -1.1800e-04,  4.0988e-05],\n",
       "          [-2.6886e-05,  8.5595e-05, -4.4968e-06,  9.5375e-06],\n",
       "          ...,\n",
       "          [ 2.1996e-04, -5.7259e-05, -7.6635e-06, -6.5438e-05],\n",
       "          [ 1.1602e-04, -1.0634e-04, -2.1000e-04,  1.9163e-04],\n",
       "          [-5.8629e-05,  1.6378e-04,  1.2684e-04, -4.3747e-05]]),\n",
       "  'base_model.model.bert.encoder.layer.1.attention.self.value.lora_A.default.weight': tensor([[ 0.0360, -0.0335, -0.0322,  ...,  0.0243, -0.0307, -0.0357],\n",
       "          [ 0.0268, -0.0151,  0.0128,  ...,  0.0006,  0.0285,  0.0339],\n",
       "          [-0.0093, -0.0137,  0.0268,  ..., -0.0209,  0.0201,  0.0009],\n",
       "          [ 0.0341, -0.0196, -0.0256,  ...,  0.0204,  0.0007,  0.0076]]),\n",
       "  'base_model.model.bert.encoder.layer.1.attention.self.value.lora_B.default.weight': tensor([[ 2.0375e-04,  8.1005e-05, -2.2031e-04,  1.2287e-04],\n",
       "          [ 4.0791e-07,  7.4464e-05, -4.4313e-05,  1.9042e-04],\n",
       "          [-1.4191e-04, -2.6416e-04,  2.5615e-04, -1.1379e-04],\n",
       "          ...,\n",
       "          [ 2.3267e-04, -1.0117e-04, -1.1115e-04, -1.1659e-04],\n",
       "          [-1.3291e-04, -9.5277e-05,  3.5116e-06,  4.6508e-05],\n",
       "          [ 1.0029e-04, -6.5207e-05, -8.9684e-06,  1.6260e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.2.attention.self.query.lora_A.default.weight': tensor([[ 0.0012,  0.0164, -0.0091,  ..., -0.0021, -0.0194,  0.0340],\n",
       "          [-0.0287,  0.0014,  0.0333,  ...,  0.0326,  0.0213, -0.0319],\n",
       "          [-0.0062, -0.0019, -0.0013,  ..., -0.0089,  0.0015,  0.0042],\n",
       "          [ 0.0064, -0.0230, -0.0268,  ..., -0.0024, -0.0309,  0.0294]]),\n",
       "  'base_model.model.bert.encoder.layer.2.attention.self.query.lora_B.default.weight': tensor([[ 1.0410e-04, -1.2091e-04,  1.0730e-05, -8.5106e-05],\n",
       "          [ 1.1825e-04,  9.6286e-05,  1.0825e-04, -2.3319e-05],\n",
       "          [ 1.7211e-04, -1.3695e-04,  6.4719e-05, -6.1047e-05],\n",
       "          ...,\n",
       "          [ 5.1946e-05,  3.6229e-06,  2.1742e-04, -1.2742e-04],\n",
       "          [-5.7937e-05, -7.4320e-05, -7.9198e-05,  5.5318e-05],\n",
       "          [-8.2143e-05,  5.5590e-05, -1.2288e-04, -1.3084e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.2.attention.self.value.lora_A.default.weight': tensor([[ 2.3247e-02,  8.8396e-03,  3.2335e-02,  ...,  2.0305e-02,\n",
       "           -2.3240e-02,  3.2351e-02],\n",
       "          [-1.2378e-02, -3.6205e-02, -3.6377e-03,  ...,  7.6095e-03,\n",
       "            2.5887e-02, -1.4602e-03],\n",
       "          [-2.8713e-02,  2.2574e-02, -4.7549e-03,  ...,  1.2293e-02,\n",
       "            1.6763e-02,  2.1149e-02],\n",
       "          [ 1.7362e-02, -1.9568e-02, -1.5476e-02,  ...,  2.2118e-02,\n",
       "           -2.5870e-03,  5.1398e-05]]),\n",
       "  'base_model.model.bert.encoder.layer.2.attention.self.value.lora_B.default.weight': tensor([[ 1.2870e-04,  7.8015e-05, -4.9488e-05, -2.5875e-05],\n",
       "          [ 5.0970e-05, -3.1480e-05, -6.7594e-05, -1.7325e-04],\n",
       "          [ 8.3892e-05, -8.6826e-05, -1.6514e-04, -1.0584e-04],\n",
       "          ...,\n",
       "          [ 5.6271e-05,  6.5836e-05,  1.6794e-04,  1.1448e-04],\n",
       "          [-3.3534e-05, -2.3699e-04, -9.9366e-05, -1.4044e-04],\n",
       "          [-1.7341e-05,  4.7451e-05,  2.7222e-04,  7.9716e-05]]),\n",
       "  'base_model.model.bert.encoder.layer.3.attention.self.query.lora_A.default.weight': tensor([[-0.0302,  0.0177, -0.0297,  ..., -0.0040, -0.0264, -0.0349],\n",
       "          [-0.0263,  0.0314, -0.0113,  ...,  0.0218, -0.0160, -0.0079],\n",
       "          [-0.0105, -0.0260, -0.0230,  ..., -0.0258, -0.0269, -0.0043],\n",
       "          [ 0.0187, -0.0041, -0.0153,  ...,  0.0298, -0.0051, -0.0162]]),\n",
       "  'base_model.model.bert.encoder.layer.3.attention.self.query.lora_B.default.weight': tensor([[-1.5978e-04,  2.2556e-04,  1.9267e-05,  5.3485e-05],\n",
       "          [-2.4010e-05,  1.3876e-04, -1.0477e-04, -7.3649e-05],\n",
       "          [-7.5523e-05,  1.1476e-04,  6.9638e-05, -1.1411e-04],\n",
       "          ...,\n",
       "          [-6.0420e-05,  1.7083e-04, -7.4875e-05,  1.5180e-05],\n",
       "          [-4.3059e-05,  1.0230e-04, -2.3079e-04,  9.3963e-05],\n",
       "          [-3.6783e-04,  4.0524e-04, -5.8105e-05, -5.9970e-05]]),\n",
       "  'base_model.model.bert.encoder.layer.3.attention.self.value.lora_A.default.weight': tensor([[-3.4080e-02,  2.5421e-02,  7.5176e-03,  ..., -4.9650e-04,\n",
       "            3.0677e-02, -2.1067e-02],\n",
       "          [-2.3931e-02, -1.1744e-05, -2.2166e-02,  ..., -1.1239e-02,\n",
       "            4.0213e-03,  2.8535e-02],\n",
       "          [ 6.6994e-04,  2.4810e-02, -1.9530e-02,  ...,  1.2541e-02,\n",
       "            1.8066e-02,  5.0375e-04],\n",
       "          [-3.0323e-02, -1.5443e-02,  1.2191e-02,  ..., -1.8917e-02,\n",
       "            8.3064e-03,  1.0146e-02]]),\n",
       "  'base_model.model.bert.encoder.layer.3.attention.self.value.lora_B.default.weight': tensor([[-2.0097e-04, -2.6221e-04, -3.4447e-04,  3.1014e-04],\n",
       "          [ 1.3657e-04,  2.5244e-04,  2.6496e-04, -3.3175e-04],\n",
       "          [ 9.0997e-05,  1.8613e-04,  3.3339e-04, -2.8001e-04],\n",
       "          ...,\n",
       "          [-5.3568e-05, -1.2120e-04, -5.8008e-05, -7.4709e-05],\n",
       "          [ 1.6831e-04, -5.0496e-05,  2.8161e-04, -1.9954e-04],\n",
       "          [ 1.3793e-04,  1.7156e-05, -2.3433e-05, -9.1397e-06]]),\n",
       "  'base_model.model.bert.encoder.layer.4.attention.self.query.lora_A.default.weight': tensor([[ 0.0220,  0.0306,  0.0198,  ...,  0.0268, -0.0315,  0.0154],\n",
       "          [-0.0251, -0.0166, -0.0287,  ..., -0.0071, -0.0298,  0.0315],\n",
       "          [ 0.0083,  0.0014,  0.0160,  ..., -0.0351, -0.0356,  0.0022],\n",
       "          [-0.0204, -0.0345, -0.0218,  ..., -0.0001, -0.0162, -0.0051]]),\n",
       "  'base_model.model.bert.encoder.layer.4.attention.self.query.lora_B.default.weight': tensor([[ 3.3746e-05,  2.1135e-04,  2.8421e-05, -8.0348e-05],\n",
       "          [-1.0157e-04, -1.1336e-04, -1.0494e-04,  1.5084e-04],\n",
       "          [ 2.9819e-05,  1.7256e-04, -1.9259e-04, -2.1858e-04],\n",
       "          ...,\n",
       "          [-2.5332e-04, -8.5373e-06, -2.0672e-05, -3.3413e-04],\n",
       "          [-7.0119e-05,  1.7633e-04, -4.3868e-05,  9.5426e-05],\n",
       "          [-1.5676e-04, -2.2137e-04,  3.7528e-05, -2.1654e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.4.attention.self.value.lora_A.default.weight': tensor([[-0.0256,  0.0251,  0.0108,  ..., -0.0183, -0.0259, -0.0307],\n",
       "          [-0.0057,  0.0163, -0.0157,  ...,  0.0035,  0.0053, -0.0279],\n",
       "          [ 0.0188, -0.0263,  0.0139,  ..., -0.0327, -0.0188, -0.0317],\n",
       "          [ 0.0225,  0.0356, -0.0140,  ..., -0.0029,  0.0145,  0.0083]]),\n",
       "  'base_model.model.bert.encoder.layer.4.attention.self.value.lora_B.default.weight': tensor([[-1.4497e-05,  4.0242e-04,  1.2525e-04, -4.3036e-04],\n",
       "          [ 1.6071e-04,  2.6044e-04,  2.8921e-04, -1.7076e-04],\n",
       "          [ 1.7685e-04, -2.4881e-04,  1.3192e-04,  4.3158e-04],\n",
       "          ...,\n",
       "          [-1.6044e-05, -3.5862e-04, -1.4637e-04,  2.7812e-04],\n",
       "          [-4.0808e-07,  1.6189e-05,  2.4257e-05,  6.5137e-05],\n",
       "          [ 1.9987e-04,  1.1009e-04,  1.5379e-04, -1.1213e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.5.attention.self.query.lora_A.default.weight': tensor([[-0.0097, -0.0062, -0.0116,  ...,  0.0005, -0.0174,  0.0257],\n",
       "          [-0.0132,  0.0119, -0.0272,  ...,  0.0052,  0.0356,  0.0116],\n",
       "          [ 0.0305, -0.0316,  0.0089,  ..., -0.0166, -0.0286,  0.0009],\n",
       "          [ 0.0158,  0.0076,  0.0111,  ...,  0.0163,  0.0198, -0.0262]]),\n",
       "  'base_model.model.bert.encoder.layer.5.attention.self.query.lora_B.default.weight': tensor([[-2.5297e-04, -7.4797e-07, -2.2315e-04,  2.3120e-04],\n",
       "          [ 3.4291e-05, -2.0293e-04,  3.5805e-05, -4.2444e-05],\n",
       "          [-2.1896e-04,  1.0832e-04, -1.4896e-04,  1.7594e-04],\n",
       "          ...,\n",
       "          [ 3.6813e-05,  3.4997e-05,  1.6789e-05, -1.0897e-04],\n",
       "          [ 1.0381e-04, -1.2154e-04,  3.2252e-05, -1.8717e-04],\n",
       "          [-5.9677e-06,  1.0101e-05,  6.0945e-05,  4.6607e-05]]),\n",
       "  'base_model.model.bert.encoder.layer.5.attention.self.value.lora_A.default.weight': tensor([[ 2.3599e-02, -1.6881e-02,  2.9616e-02,  ...,  3.8349e-05,\n",
       "            1.8070e-02,  1.8397e-02],\n",
       "          [ 3.4281e-02, -2.2942e-02,  7.4545e-03,  ...,  2.3502e-02,\n",
       "           -1.1952e-02, -3.3400e-02],\n",
       "          [-8.4755e-03,  1.0706e-03,  2.4962e-02,  ...,  1.3637e-02,\n",
       "           -1.3199e-03, -1.9034e-04],\n",
       "          [ 2.4190e-02,  3.4295e-02,  5.2653e-03,  ..., -1.2195e-02,\n",
       "            2.1811e-02, -1.8721e-02]]),\n",
       "  'base_model.model.bert.encoder.layer.5.attention.self.value.lora_B.default.weight': tensor([[ 1.9501e-04, -8.7403e-05,  2.1858e-04, -4.0324e-05],\n",
       "          [-3.7382e-04,  4.2463e-04, -3.2959e-04,  2.8804e-04],\n",
       "          [-5.2122e-04,  1.8701e-04, -2.8811e-04,  1.0047e-04],\n",
       "          ...,\n",
       "          [-1.7451e-04,  2.1254e-04, -2.4026e-04,  1.3274e-04],\n",
       "          [-2.9131e-04,  2.9009e-04, -2.4812e-04,  2.4667e-04],\n",
       "          [-4.0341e-05,  8.1673e-05, -1.0226e-04,  6.2554e-06]]),\n",
       "  'base_model.model.bert.encoder.layer.6.attention.self.query.lora_A.default.weight': tensor([[-0.0277,  0.0213,  0.0045,  ...,  0.0304, -0.0293, -0.0151],\n",
       "          [ 0.0177, -0.0077, -0.0058,  ...,  0.0311,  0.0329,  0.0061],\n",
       "          [ 0.0129, -0.0046,  0.0177,  ..., -0.0144, -0.0331,  0.0187],\n",
       "          [ 0.0216, -0.0081, -0.0043,  ...,  0.0336,  0.0246,  0.0235]]),\n",
       "  'base_model.model.bert.encoder.layer.6.attention.self.query.lora_B.default.weight': tensor([[-1.8387e-04, -8.4574e-05, -1.4607e-05,  1.5692e-04],\n",
       "          [ 1.9913e-04,  1.2331e-05,  4.7552e-05, -3.6463e-05],\n",
       "          [ 6.5311e-05,  1.3526e-05,  2.0812e-05,  1.9197e-05],\n",
       "          ...,\n",
       "          [ 9.9042e-05,  1.0689e-04,  2.1309e-04, -4.6781e-05],\n",
       "          [-8.5854e-05,  8.1972e-05, -5.6994e-05, -2.0589e-04],\n",
       "          [-5.9190e-05, -4.3085e-05,  1.3790e-04, -3.8675e-06]]),\n",
       "  'base_model.model.bert.encoder.layer.6.attention.self.value.lora_A.default.weight': tensor([[ 0.0277,  0.0238, -0.0177,  ..., -0.0193, -0.0063,  0.0056],\n",
       "          [ 0.0306, -0.0131, -0.0343,  ..., -0.0337,  0.0005,  0.0195],\n",
       "          [ 0.0138,  0.0334,  0.0011,  ..., -0.0047,  0.0076, -0.0043],\n",
       "          [-0.0286, -0.0050,  0.0359,  ...,  0.0014,  0.0291, -0.0007]]),\n",
       "  'base_model.model.bert.encoder.layer.6.attention.self.value.lora_B.default.weight': tensor([[-1.8026e-04, -1.2967e-04,  1.4074e-04, -1.8036e-04],\n",
       "          [-3.1610e-04, -3.5264e-04,  3.1395e-04, -3.3366e-04],\n",
       "          [ 2.9166e-04,  2.9751e-04, -3.0038e-04,  3.1355e-04],\n",
       "          ...,\n",
       "          [ 1.9663e-04,  5.8827e-05, -5.8780e-05,  1.3513e-05],\n",
       "          [-2.4507e-04,  1.0003e-04,  2.1819e-04,  1.0735e-04],\n",
       "          [ 9.2947e-05,  2.5899e-04, -5.7259e-05,  2.8042e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.7.attention.self.query.lora_A.default.weight': tensor([[-0.0160, -0.0016,  0.0355,  ..., -0.0334, -0.0136, -0.0169],\n",
       "          [ 0.0218, -0.0255,  0.0205,  ..., -0.0049, -0.0093,  0.0289],\n",
       "          [-0.0033, -0.0024,  0.0174,  ..., -0.0029, -0.0049,  0.0084],\n",
       "          [ 0.0264, -0.0357, -0.0360,  ..., -0.0274,  0.0197, -0.0053]]),\n",
       "  'base_model.model.bert.encoder.layer.7.attention.self.query.lora_B.default.weight': tensor([[ 2.1859e-04,  8.3750e-05,  2.3483e-05,  1.1415e-04],\n",
       "          [ 7.1896e-05,  1.5203e-05,  7.2765e-06, -9.6892e-06],\n",
       "          [ 1.0613e-04, -3.5988e-05,  1.3681e-04,  2.2450e-04],\n",
       "          ...,\n",
       "          [ 2.2380e-06,  1.2447e-04,  4.3170e-05, -8.9919e-05],\n",
       "          [-1.9632e-05, -9.7641e-05,  1.6556e-04, -1.7282e-05],\n",
       "          [-1.6486e-05, -2.1929e-04, -1.3849e-04,  1.4295e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.7.attention.self.value.lora_A.default.weight': tensor([[ 0.0204,  0.0083,  0.0339,  ...,  0.0302, -0.0099, -0.0226],\n",
       "          [-0.0254, -0.0307,  0.0176,  ...,  0.0102, -0.0100,  0.0170],\n",
       "          [-0.0340,  0.0336, -0.0157,  ...,  0.0265, -0.0056,  0.0340],\n",
       "          [ 0.0242,  0.0061, -0.0278,  ...,  0.0168,  0.0055,  0.0285]]),\n",
       "  'base_model.model.bert.encoder.layer.7.attention.self.value.lora_B.default.weight': tensor([[-1.2729e-04,  1.4774e-04,  3.0694e-04, -2.9886e-04],\n",
       "          [-1.1653e-04, -3.1349e-04, -4.3325e-04,  2.7340e-04],\n",
       "          [-2.4055e-04,  2.2462e-04,  1.3627e-04, -2.5756e-04],\n",
       "          ...,\n",
       "          [ 3.9417e-04, -3.4826e-04, -3.3236e-04,  3.5212e-04],\n",
       "          [ 1.9699e-05, -3.7515e-05,  4.9613e-05,  1.0993e-04],\n",
       "          [ 4.2153e-04, -3.6659e-04, -4.1354e-04,  4.1197e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.8.attention.self.query.lora_A.default.weight': tensor([[ 0.0040,  0.0160,  0.0031,  ..., -0.0340,  0.0295, -0.0260],\n",
       "          [ 0.0257, -0.0122, -0.0147,  ..., -0.0149,  0.0247,  0.0104],\n",
       "          [-0.0074, -0.0025,  0.0180,  ..., -0.0179, -0.0218,  0.0237],\n",
       "          [ 0.0060,  0.0047, -0.0310,  ...,  0.0330,  0.0169, -0.0252]]),\n",
       "  'base_model.model.bert.encoder.layer.8.attention.self.query.lora_B.default.weight': tensor([[-7.6918e-05, -8.7579e-05, -9.7768e-05,  1.1948e-04],\n",
       "          [-1.1891e-04,  2.3316e-04, -8.9799e-06,  2.9335e-04],\n",
       "          [ 1.1163e-04,  2.0656e-04, -1.6377e-04,  7.1105e-05],\n",
       "          ...,\n",
       "          [-6.1596e-05,  1.7950e-05,  5.8993e-05,  3.6327e-05],\n",
       "          [ 1.0966e-04,  3.9061e-05, -8.0375e-05, -9.6443e-05],\n",
       "          [ 2.3354e-04,  1.1323e-04,  4.8068e-05,  1.0116e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.8.attention.self.value.lora_A.default.weight': tensor([[ 0.0238,  0.0012, -0.0266,  ...,  0.0222,  0.0056,  0.0085],\n",
       "          [ 0.0233, -0.0310,  0.0037,  ...,  0.0196,  0.0248,  0.0142],\n",
       "          [-0.0206,  0.0127,  0.0216,  ..., -0.0219, -0.0091, -0.0087],\n",
       "          [-0.0036,  0.0270,  0.0176,  ..., -0.0289,  0.0227,  0.0070]]),\n",
       "  'base_model.model.bert.encoder.layer.8.attention.self.value.lora_B.default.weight': tensor([[-3.9947e-04,  9.3837e-05,  1.0151e-04, -2.7261e-04],\n",
       "          [-4.4880e-04,  1.5496e-04,  3.6094e-04, -4.2239e-04],\n",
       "          [-1.8594e-04,  4.9706e-05,  3.9964e-05, -1.7729e-04],\n",
       "          ...,\n",
       "          [ 5.3470e-04,  2.9707e-04, -1.8773e-04,  3.8568e-04],\n",
       "          [ 5.2894e-04,  1.9305e-04, -1.2757e-04,  3.3654e-04],\n",
       "          [ 5.1768e-04,  1.2077e-04, -2.2105e-05,  3.3018e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.9.attention.self.query.lora_A.default.weight': tensor([[ 0.0284,  0.0136, -0.0164,  ...,  0.0145, -0.0253,  0.0137],\n",
       "          [-0.0092,  0.0339, -0.0008,  ...,  0.0318,  0.0039, -0.0351],\n",
       "          [-0.0236, -0.0199, -0.0296,  ..., -0.0271,  0.0284,  0.0355],\n",
       "          [ 0.0025, -0.0324, -0.0270,  ...,  0.0353, -0.0211, -0.0173]]),\n",
       "  'base_model.model.bert.encoder.layer.9.attention.self.query.lora_B.default.weight': tensor([[ 1.8776e-04,  2.9749e-04, -1.4751e-06,  2.2716e-04],\n",
       "          [ 8.7331e-06, -2.2934e-04,  4.9820e-05, -4.4702e-05],\n",
       "          [ 4.6171e-05, -4.6907e-05,  9.2418e-05, -1.3351e-04],\n",
       "          ...,\n",
       "          [-7.2321e-05,  2.5512e-04,  5.0895e-05,  1.7561e-04],\n",
       "          [-6.9413e-05, -2.0347e-04,  1.0989e-04, -3.8931e-04],\n",
       "          [ 1.8322e-04, -4.4676e-05,  2.6571e-04, -1.5294e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.9.attention.self.value.lora_A.default.weight': tensor([[-0.0351, -0.0153,  0.0131,  ...,  0.0063,  0.0100,  0.0274],\n",
       "          [ 0.0026, -0.0033, -0.0329,  ..., -0.0169, -0.0288,  0.0169],\n",
       "          [ 0.0001,  0.0323, -0.0161,  ..., -0.0024, -0.0056, -0.0179],\n",
       "          [ 0.0063, -0.0177, -0.0155,  ..., -0.0103, -0.0090,  0.0211]]),\n",
       "  'base_model.model.bert.encoder.layer.9.attention.self.value.lora_B.default.weight': tensor([[ 3.8864e-04, -4.1954e-04,  5.2953e-04,  1.5389e-04],\n",
       "          [ 3.2807e-04, -4.2249e-04,  5.3677e-04,  1.4390e-04],\n",
       "          [-9.0634e-05,  5.4238e-05, -2.1464e-04, -1.5308e-04],\n",
       "          ...,\n",
       "          [ 1.6881e-05, -3.8885e-05,  5.7282e-05,  4.1940e-05],\n",
       "          [-4.0848e-05, -8.9810e-05,  3.5197e-05, -1.7231e-05],\n",
       "          [-5.8075e-04,  6.8804e-04, -6.2338e-04, -5.9006e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.10.attention.self.query.lora_A.default.weight': tensor([[-0.0121, -0.0165,  0.0324,  ..., -0.0278,  0.0160, -0.0274],\n",
       "          [-0.0152, -0.0350, -0.0124,  ..., -0.0195, -0.0118, -0.0048],\n",
       "          [ 0.0007,  0.0227, -0.0257,  ...,  0.0244,  0.0073, -0.0046],\n",
       "          [-0.0300,  0.0302, -0.0288,  ..., -0.0008,  0.0065,  0.0062]]),\n",
       "  'base_model.model.bert.encoder.layer.10.attention.self.query.lora_B.default.weight': tensor([[ 1.6588e-04,  1.9538e-04,  2.6963e-04,  6.8323e-05],\n",
       "          [-1.4822e-04, -6.6226e-05, -5.7895e-05,  9.3704e-05],\n",
       "          [ 7.1724e-05, -1.6641e-04, -1.0477e-04, -3.0639e-05],\n",
       "          ...,\n",
       "          [-1.2659e-04, -4.1772e-05,  3.8602e-06,  1.7233e-04],\n",
       "          [ 1.1608e-04,  6.5584e-05,  3.0331e-04,  1.0368e-04],\n",
       "          [ 3.0546e-04,  2.8307e-04,  2.7229e-04,  1.4957e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.10.attention.self.value.lora_A.default.weight': tensor([[-6.1682e-03, -3.3157e-02,  2.1788e-02,  ...,  5.1721e-03,\n",
       "            3.4325e-02,  2.3475e-02],\n",
       "          [ 7.8527e-03, -1.0043e-02,  2.5493e-02,  ...,  7.0934e-03,\n",
       "            3.6942e-02, -3.7096e-02],\n",
       "          [-2.2576e-03,  7.6133e-03, -2.6712e-02,  ...,  2.0316e-02,\n",
       "           -1.8549e-02,  2.2006e-02],\n",
       "          [ 3.3789e-03,  2.4527e-02, -4.3417e-03,  ..., -1.4026e-02,\n",
       "            5.9630e-05,  6.6156e-03]]),\n",
       "  'base_model.model.bert.encoder.layer.10.attention.self.value.lora_B.default.weight': tensor([[-3.9816e-04, -5.6319e-04,  3.1696e-04,  1.2217e-04],\n",
       "          [-2.2575e-04, -3.8593e-04,  7.1504e-05, -8.8456e-05],\n",
       "          [-5.2977e-04, -5.8275e-04,  3.4508e-04, -7.8993e-05],\n",
       "          ...,\n",
       "          [-1.1284e-04, -4.4389e-04,  2.9355e-04, -1.5120e-04],\n",
       "          [-6.2446e-04, -6.2926e-04,  4.3609e-04,  1.4313e-04],\n",
       "          [-1.2836e-04, -1.2099e-04,  1.2787e-04,  1.6410e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.11.attention.self.query.lora_A.default.weight': tensor([[-0.0090, -0.0032, -0.0280,  ..., -0.0158,  0.0180, -0.0036],\n",
       "          [ 0.0195, -0.0256, -0.0277,  ...,  0.0289,  0.0123,  0.0189],\n",
       "          [-0.0145, -0.0308,  0.0124,  ..., -0.0117,  0.0345, -0.0314],\n",
       "          [-0.0188,  0.0024,  0.0239,  ..., -0.0325, -0.0206,  0.0303]]),\n",
       "  'base_model.model.bert.encoder.layer.11.attention.self.query.lora_B.default.weight': tensor([[ 1.0032e-04,  5.6419e-05,  1.1454e-04, -2.0558e-04],\n",
       "          [ 1.7950e-04,  2.3619e-04,  3.5443e-04,  1.0726e-05],\n",
       "          [-1.4498e-04, -1.5169e-04, -1.0095e-04,  2.5261e-04],\n",
       "          ...,\n",
       "          [ 4.5488e-05,  4.8389e-04,  3.6344e-04, -3.0116e-04],\n",
       "          [ 2.1082e-04, -2.2490e-04, -1.0413e-04, -5.5748e-06],\n",
       "          [ 3.7530e-04,  1.7597e-04,  3.3984e-04, -2.9554e-04]]),\n",
       "  'base_model.model.bert.encoder.layer.11.attention.self.value.lora_A.default.weight': tensor([[ 0.0205,  0.0314, -0.0249,  ...,  0.0093, -0.0196, -0.0216],\n",
       "          [-0.0081, -0.0249, -0.0231,  ..., -0.0265, -0.0274,  0.0261],\n",
       "          [-0.0179,  0.0141,  0.0109,  ..., -0.0292, -0.0309,  0.0218],\n",
       "          [ 0.0267,  0.0350, -0.0357,  ..., -0.0062, -0.0294, -0.0001]]),\n",
       "  'base_model.model.bert.encoder.layer.11.attention.self.value.lora_B.default.weight': tensor([[-2.5651e-04, -1.5244e-04, -1.1131e-04, -1.4396e-04],\n",
       "          [ 3.1655e-04,  6.7464e-04,  5.2732e-04,  4.2399e-04],\n",
       "          [-4.1740e-04, -5.3118e-04, -3.8734e-04, -4.7705e-04],\n",
       "          ...,\n",
       "          [-1.3213e-04, -4.0973e-04, -2.1267e-04, -6.5111e-05],\n",
       "          [-3.4546e-04, -5.2480e-04, -2.7611e-04, -3.1888e-04],\n",
       "          [-3.6762e-04, -3.2982e-04, -1.8495e-04, -4.5498e-04]]),\n",
       "  'base_model.model.classifier.modules_to_save.default.weight': tensor([[ 0.0177,  0.0066,  0.0211,  ...,  0.0053, -0.0182, -0.0382],\n",
       "          [-0.0278, -0.0350,  0.0015,  ...,  0.0276,  0.0241, -0.0005]]),\n",
       "  'base_model.model.classifier.modules_to_save.default.bias': tensor([-0.0004,  0.0004])},\n",
       " -0.03286843710739947)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(global_model.parameters(), lr=1e-5)\n",
    "local_model.update_weights_with_ripple(local_model.train_set, local_model.ref_set, global_model, global_round=1, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f14bc157a8847d6bd726175b858ed35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/132 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|---- Test ACC: 82.38%\n",
      "|---- Test ASR: 11.36%\n"
     ]
    }
   ],
   "source": [
    "global_model.to('mps')\n",
    "test_acc, _ = test_inference(args, global_model, test_dataset)\n",
    "test_asr, _ = test_inference(args,global_model, attack_test_set)\n",
    "print(\"|---- Test ACC: {:.2f}%\".format(100 * test_acc))\n",
    "print(\"|---- Test ASR: {:.2f}%\".format(100 * test_asr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
